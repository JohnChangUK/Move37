# Value of given state - # V(S) 
# maxa - Max action of all the actions avaiable in the state we're in
# V(S) = maxa(R(s, a) + yV(s'))
# s - State
# a - Action
# R - Reward
# y(Gamma) - Discount factor
# Policy - What are the best actions of the given state the agent is in?
# To maximise the future total discounted reward
# Sigma - Sum of all these values on right
# T is the horizon, (the episode length, aka episode for a game; from start to finish)
